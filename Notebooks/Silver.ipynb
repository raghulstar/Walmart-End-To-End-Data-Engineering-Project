{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f6dc72e-e445-4695-816a-95a31c8d28bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = spark.read.format('delta')\\\n",
    "                    .option('inferSchema',True)\\\n",
    "                    .option('header',True)\\\n",
    "                    .load('dbfs:/mnt/walmartsilver/Train Silver/')\n",
    "test_df = spark.read.format('delta')\\\n",
    "                    .option('inferSchema',True)\\\n",
    "                    .option('header',True)\\\n",
    "                    .load('dbfs:/mnt/walmartsilver/Test Silver/')\n",
    "features_df = spark.read.format('delta')\\\n",
    "                    .option('inferSchema',True)\\\n",
    "                    .option('header',True)\\\n",
    "                    .load('dbfs:/mnt/walmartsilver/Features Silver/')\n",
    "stores_df = spark.read.format('delta')\\\n",
    "                    .option('inferSchema',True)\\\n",
    "                    .option('header',True)\\\n",
    "                    .load('dbfs:/mnt/walmartsilver/Stores Silver/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74d224f7-4b51-4359-98c4-98240be59694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Join Train Dataset with Stores Dataset on \"Store\"\n",
    "train_stores_df = train_df.join(stores_df, on=\"Store\", how=\"left\")\n",
    "\n",
    "# Step 2: Join Train Dataset with Features Dataset on \"Store\", \"Date\", and \"IsHoliday\"\n",
    "final_train_df = train_stores_df.join(\n",
    "    features_df, \n",
    "    on=[\"Store\", \"Date\", \"IsHoliday\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Joining Test Dataset\n",
    "# -------------------------\n",
    "\n",
    "# Step 1: Join Test Dataset with Stores Dataset on \"Store\"\n",
    "test_stores_df = test_df.join(stores_df, on=\"Store\", how=\"left\")\n",
    "\n",
    "# Step 2: Join Test Dataset with Features Dataset on \"Store\", \"Date\", and \"IsHoliday\"\n",
    "final_test_df = test_stores_df.join(\n",
    "    features_df, \n",
    "    on=[\"Store\", \"Date\", \"IsHoliday\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05251747-aa43-4485-95f5-b251eaec5457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c05cd381-a2be-428b-85b6-98d3c37e6191",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9a2ae04-4048-4565-97df-13e1fb077c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"dbfs:/mnt/walmartsilver/Final Silver/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b315cea3-19a3-4932-bfcf-afacc43c0381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/mnt/walmartsilver/Final Silver/\"\n",
    "\n",
    "# Function to overwrite Delta files cleanly\n",
    "def write_clean_delta(df, folder_name):\n",
    "    path = f\"{base_path}{folder_name}\"\n",
    "    # Remove the contents of the directory to ensure a clean overwrite\n",
    "    files = dbutils.fs.ls(path)\n",
    "    for file in files:\n",
    "        dbutils.fs.rm(file.path, True)\n",
    "    # Write the DataFrame in Delta format\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(path)\n",
    "\n",
    "# Write each DataFrame to its respective folder\n",
    "write_clean_delta(final_train_df, \"Train Silver\")\n",
    "write_clean_delta(final_test_df, \"Test Silver\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}